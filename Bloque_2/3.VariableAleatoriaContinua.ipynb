{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# I.1 Variable aleatoria. Funciones de distribución y densidad\n",
    "\n",
    "Recordemos que llamamos **espacio de probabilidad** a la terna $\\mathscr{E}(\\Omega, \\mathscr{F}, P)$ donde:\n",
    "\n",
    "* $\\Omega$ es el **espacio muestral** o conjunto de todos los resultados posibles del experimento aleatorio, formado por elementos **discretos** o definido de forma **continua**.\n",
    "* $\\mathscr{F}$ es el **conjunto de todos los sucesos** con resultados en $\\Omega$:\n",
    "  * $\\emptyset, \\Omega \\subset \\mathscr{F}$. \n",
    "  * $A, B \\subset \\mathscr{F} \\implies \\left\\{\\begin{matrix}\n",
    "  A \\cup B \\subset \\mathscr{F} \\\\\n",
    " A \\cap B \\subset \\mathscr{F}\n",
    " \\end{matrix}\\right.$\n",
    "  \n",
    "* **P es una ley que asigna probabilidades a los sucesos** de $\\mathscr{F}$\n",
    "\n",
    "$$\\begin{align*}\n",
    "P:  \\mathscr{F} & \\longmapsto [0, 1]\\\\\n",
    "   A, B & \\longmapsto P(A), P(B)\\\\\n",
    "   \\emptyset & \\longmapsto 0\\\\\n",
    "   \\Omega & \\longmapsto 1\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "$$P(A \\cup B) = P(A)+P(B)-P(A\\cap B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variable aleatoria\n",
    "\n",
    "Dado el **espacio de probabilidad** $\\mathscr{E}(\\Omega, \\mathscr{F}, P)$, definimos la **variable aleatoria** $X$\n",
    "\n",
    "$$\\begin{align*}\n",
    "X:  \\mathscr{\\Omega} & \\longmapsto \\mathbb{R}\\\\\n",
    "   \\alpha & \\longmapsto X(\\alpha)\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "asignando a cada resultado del espacio muestral un número real, con las condiciones:\n",
    "* $\\left\\{X \\leq x \\right\\}$, esto es, el conjunto formado por todos los elementos muestrales que al transformarse por la variable aleatoria son menores que $x$, es un suceso de $\\mathscr{F}$.\n",
    "* Son también sucesos de $\\mathscr{F}$, con la misma interpretación:\n",
    "   * $\\left\\{x_1 \\leq X \\leq x_1 \\right\\}$ \n",
    "   * $\\left\\{X = x \\right\\}$\n",
    "   * Los resultados de todas las operaciones conjuntistas sobre la recta real de sucesos definidos de las maneras anteriores.\n",
    "* Lógicamente, cada uno de los sucesos definidos con intervalos o elementos de la recta real tienen probabilidades asociadas, pues son sucesos del espacio de probabilidad.\n",
    "* Debe cumplirse que $P(\\left\\{X = \\infty \\right\\})=P(\\left\\{X = -\\infty \\right\\})=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo de variable aleatoria discreta: dado\n",
    "\n",
    "Consideremos un dado bueno (no trucado) cuyas caras están indicadas por las seis primeras letras del abecedario. El espacio de probbailidad es:\n",
    "* Espacio muestral $\\Omega=\\left\\{a, b, c, d, e, f\\right\\}$.\n",
    "* $\\mathscr{F}$ está formado por $2^6 = 64$ sucesos, incluyendo $\\emptyset$ y $\\Omega$, entre ellos, por ejemplo, $\\{a\\}, \\{a, c\\}, \\{d,e,f,\\}, \\{b,c,e,f\\}, \\{b,c,d,e,f\\},\\ldots$\n",
    "* Cada suceso tiene asignada una probabilidad fácilmente obtenible considerando que $P(a)=P(b)=P(c)=P(d)=P(e)=P(f)=1/6$ y aplicando la probabilidad de la unión de sucesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Definamos la variable aleatoria $X: \\Omega \\longmapsto \\mathbb{R}$ \n",
    "$$X(a)=1, X(b)=2, X(c)=3, X(d)=4, X(e)=5, X(f)=6$$ \n",
    "\n",
    "Veamos algunos sucesos y sus probabilidades:\n",
    "* $\\{X > 7\\} = \\emptyset \\implies P(\\{X > 7\\})=0$\n",
    "* $\\{X \\leq 6.001\\} = \\Omega \\implies P(\\{X \\leq 6.001\\})=1$\n",
    "* $\\{X=3\\} = \\{c\\} \\implies P(\\{X=3\\})=1/6$\n",
    "* $\\{3< X \\leq 5\\} = \\{d, e\\} \\implies P(\\{3< X \\leq 5\\})=2/6=1/3$\n",
    "* $\\{X \\leq 3.5\\} = \\{a, b, c\\} \\implies P(\\{X \\leq 3.5\\})=3/6=1/2$\n",
    "* $\\{4 < X \\leq 4.999\\} = \\emptyset \\implies P(\\{4 < X \\leq 4.999\\})=0$\n",
    "* $\\{X \\leq 3.5\\}\\cup \\{X \\leq 5\\} = \\{X \\leq 5\\} = \\{a, b, c, d ,e\\} \\implies P\\left(\\{X \\leq 3.5\\}\\cup \\{X \\leq 5\\}\\right)=P\\left(\\{X \\leq 5\\}\\right)=5/6$\n",
    "* $\\{X \\leq 3.5\\}\\cap \\{X \\leq 5\\} = \\{X \\leq 3.5\\} = \\{a, b, c\\} \\implies P\\left(\\{X \\leq 3.5\\}\\cap \\{X \\leq 5\\}\\right)=P\\left(\\{X \\leq 3.5\\}\\right)=3/6=1/2$\n",
    "\n",
    "Adviértase que \n",
    "\n",
    "$$P\\left(\\{X \\leq 3.5\\}\\cup \\{X \\leq 5\\}\\right) =\\\\ P\\left(\\{X \\leq 3.5\\}\\right) + P\\left(\\{X \\leq 5\\}\\right) - P\\left(\\{X \\leq 3.5\\}\\cap \\{X \\leq 5\\}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo de variable continua: tiempo de llegada\n",
    "\n",
    "Consideremos un hecho que acontece aleatoriamente dentro de un intervalo de tiempo $[T_0, T_1]$. Por ejemplo, una llamada telefónica del padre o la madre que siempre acontece entre las 22h y las 23h. Sabemos que siempre se produce la llamada, pero lo hara de forma igualmente aleatoria a lo largo del intervalo. \n",
    "\n",
    "El espacio muetsral $\\Omega$ está formado por el intervalo con los infinitos instantes en los que puede acontecer el hecho, definidos sobre un eje temporal **continuo**, delimitados por los instantes $T_0$ y $T_1$. Los distintos subintervalos dentro del intervalo forman el espacio de sucesos $\\mathscr{F}$, asignándose probabilidades a cada uno como sigue:\n",
    "\n",
    "$$P(\\{t_a,t_b\\})= \\frac{t_b-t_a}{T_1-T_0}$$\n",
    "\n",
    "donde $\\{t_a,t_b\\}$ representa el subintervalo cuya probabilidad se desea calcular. En el ejemplo anterior, la probailidad de que la llamada acontezca entre 22:15h y 22:30h es de 0.25. Adviértase que **la probabilidad del hecho en un único instante es nula**, pues dicho instante se determina estrechando el subintervalo hasta el límite:\n",
    "\n",
    "$$P(\\{(t-\\frac{\\Delta}{2}),(t+\\frac{\\Delta}{2})\\})= \\frac{(t+\\frac{\\Delta}{2})-(t-\\frac{\\Delta}{2})}{T_1-T_0}\n",
    "      \\xrightarrow[\\Delta \\to 0]{} 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En este caso, el espacio muestral continuo suele ya estar definido numéricamente, lo que implícitamente define una variable aleatoria. Veamos algunos intervalos para nuestro ejemplo de llamada, definiendo la variable aleatoria $X(t) = t$ sobre todo el eje real, convirtiendo los minutos, segundos y demás subunidades. Por ejemplo, las 22:15 corresponde 22.25, pues quince minutos es un cuarto de hora \n",
    "\n",
    "* $P(\\{X=22.30\\}) = 0$ pues la **probabilidad de cualquier instante siempre es nula**.\n",
    "* $P(\\{X < 22\\})=P(\\emptyset)=0$\n",
    "* $P(\\{X \\leq 22\\})=P(\\{22\\})=0$\n",
    "* $P(\\{X \\leq 22.75\\})=3/4$\n",
    "* $P(\\{X > 22.75\\}) = 1 - P(\\{X \\leq 22.75\\}) = 1/4$\n",
    "* $P(22.25 < X \\leq 22.75) = 1/2$\n",
    "* $P(X \\leq 23) = P(\\Omega) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Función de distribución de probabilidad\n",
    "\n",
    "Puede demostrarse que cualquier suceso de $\\mathscr{F}$ puede obtenerse mediante opoeraciones conjutistas realizadas sobre sucesos definidos sobre semi-intervalos de la forma $\\{X\\leq x\\}$ donde $x \\in \\mathbb{R}$ es un nñumero real arbitrario. Si se tienen las probabilidades de tales sucesos se conoce totalmente el espacio de probabilidad de la variable aleatoria, lo que justifica la definición de **función de distribución de probabilidad** como:\n",
    "\n",
    "$$F_X(x) = P(\\{X\\leq x\\}) \\quad -\\infty \\leq x \\leq \\infty$$\n",
    "\n",
    "El **cuantil** $x_q$ corresponde al valor que hace que el $q\\%$ de la distribución esté por debajo. Por tanto, $q = F_X(x_q) \\implies x_q = F_X^{-1}(q)$ y $F_X^{-1}$ se llama **función cuantil**. Por ejemplo,\n",
    "* El primer cuartil es $x_{0.25} = F_X^{-1}(0.25)$\n",
    "* La mediana o segundo cuartil es $x_{0.5} = F_X^{-1}(0.5)$\n",
    "* El tercer cuartil es $x_{0.75} = F_X^{-1}(0.75)$\n",
    "* El octavo decil es $x_{0.8} = F_X^{-1}(0.8)$\n",
    "* El décimoquinto percentil es $x_{0.15} = F_X^{-1}(0.15)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Propiedades de la función de distribución de probabilidad\n",
    "\n",
    "Sean $F_X(x^-)=\\lim \\limits_{\\epsilon \\to 0} F_X(x-\\epsilon)$ y $F_X(x^+)=\\lim \\limits_{\\epsilon \\to 0} F_X(x+\\epsilon)$ los valores de la función de distribución en $x$ al acercarse respectivamente por la izquierda y por la derecha. Se cumplen las siguientes propiedades:\n",
    "\n",
    "1. $F_X(-\\infty) = 0 \\quad F_X(+\\infty) = 1$\n",
    "2. $P(\\{X>x\\})=1-F_X(x)$\n",
    "3. $F_X$ es continua por la derecha: $F_X(x^+)=F_X(x)$\n",
    "4. Si la variable aleatoria es continua, $F_X$ también lo es y $F_X(x^-)=F_X(x)$\n",
    "4. $F_X$ es no decreciente: $x_1 < x_2 \\implies F_X(x_1)\\leq F_X(x_2)$\n",
    "5. $F_X(x_0)=0 \\implies F_X(x) = \\forall x \\leq x_0$\n",
    "6. En los puntos de discontinuidad, $P(\\{X = x\\})=F_X(x)-F_X(x^-)$\n",
    "7. $P(\\{x_1<X\\leq x_2\\})=F_X(x_2)-F_X(x_1)$\n",
    "8. $P(\\{x_1 \\leq X\\leq x_2\\})=F_X(x_2)-F_X(x_1^-)$\n",
    "9. Si la **variable aleatoria es discreta**, la función de distribución es constante salvo en los puntos de discontinuidad en los que se sitúan los sucesos muestrales elementales.\n",
    "10. La **variable aleatoria puede ser mixta**, con sucesos muestrales con probabilidad finita no nula y otros definidos sobre un continuo con probabilidades elementales nulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Función de densidad de probabilidad\n",
    "\n",
    "Suele ser conveniente hacer un símil entre probabilidad y masa, de modo que nuestra distribución de probabilidad a lo largo de probabilidad podemos interpretarla como una masa igualmente distribuida a lo largo del eje.\n",
    "\n",
    "Si la **variable es discreta**, tendremos **masas puntuales** ideales mientras que si la **variable es continua**, la masa se distribuirá concentrándose más o menos a lo largo del eje, pero sin llegar a formar masas puntuales. La **variable mixta** combina ambos tipos de masa a lo largo del eje.\n",
    "\n",
    "Como ya se ha visto, **la función de distribución describe la masa acumulada hasta una posición** y, por diferencias, puede calcularse la masa de cualquier intervalo.\n",
    "\n",
    "La **función de densidad**, como su nombre indica, describe la densidad de masa (masa por unidad de longitud) a lo largo del eje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **función de densidad de probabilidad** (fdp) se define:\n",
    "\n",
    "$$f_X(x) =\\frac{dF_X(x)}{dx}=\\lim \\limits_{\\Delta x \\to 0} \\frac{F_X(x+\\Delta x/2)-F_X(x-\\Delta x/2)}{\\Delta x}= \n",
    "\\lim \\limits_{\\Delta x \\to 0} \\frac{P\\left(\\{(x-\\Delta x/2) < x \\leq (x+\\Delta x/2)\\}\\right)}{\\Delta x}\n",
    "$$\n",
    "\n",
    "Si **la variable aleatoria es continua**, \n",
    "$$P\\left(\\{(x-\\Delta x/2) < x \\leq (x+\\Delta x/2)\\}\\right) \\approx f_X(x)\\Delta x$$\n",
    "\n",
    "Si **la variable aleatoria es discreta**, $F_X(x)$ resulta discontinua por la izquierda en los puntos donde se localizan masas de probabilidad y no es derivable en los mismos. En tales puntos ${x_i}$ puede definirse una **función de masa de probabilidad** $p_X(x_i)=P(\\{X=x_i\\})$.\n",
    "\n",
    "Matemáticamente, puede usuarse la función $\\delta(x)$, que tiene **área uno** localizada en $x=0$, anchura nula y altura infinita para relacionar las funciones de masa y de densidad de probabilidad. Si la variable aleatoria es discreta:\n",
    "$$f_X(x)=\\sum_{i}p_X(x_i)\\delta(x-x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Propiedades de la función de densidad de probabilidad (fdp)\n",
    "\n",
    "La función de distribución de probabilidad (fdp) se obtiene integrando:\n",
    "\n",
    "$$f_X(x) = \\frac{dF_X(x)}{dx} \\iff F_X(x)=\\int_{-\\infty}^x f_X(u)du$$\n",
    "\n",
    "Dado que $F_X(\\infty)=1$ se concluye que $\\int_{-\\infty}^{\\infty} f_X(x)dx = 1$. \n",
    "\n",
    "Por tanto, el área debajo de la función de densidad de probabilidad **siempre** es uno. Esto es lógico, pues el eje real corresponde al espacio muestral o suceso seguro.\n",
    "\n",
    "La probabilidad de un intervalo es\n",
    "$$P(x_1< X \\leq x_2) = F_X(x_2)-F_X(x_1)=\\int_{x_1}^{x_2}f_X(x)dx$$\n",
    "\n",
    "y corresponde al área debajo de la curva de la fdp en dicho intervalo. Adviértase que $\\int_{0^-}^{0^+}\\delta(x)dx = 1$, lo que nos permite extender el formalismo a variables discretas y mixtas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Propiedades de la función de masa de probabilidad (fmp)\n",
    "\n",
    "Como ya se ha visto, cuando la variable aleatoria es discreta, se define la **función de masa de probabilidad**, que se relaciona como sigue con la fdp:\n",
    "\n",
    "$$p_X(x_i)=P(\\{X=x_i\\})\\iff f_X(x)=\\sum_{i}p_X(x_i)\\delta(x-x_i)$$\n",
    "\n",
    "Podemos relacionar la función de masa de probabilidad (fmp) con la función de distribución de probabilidad (FDP):\n",
    "\n",
    "$$p_X(x_n) = F_X(x_n)-F_X(x_{n-1}) \\iff F_x(x_n)=\\sum_{i=-\\infty}^n p_X(x_i)$$\n",
    "\n",
    "Siguen fácilmente las siguientes propiedades:\n",
    "\n",
    "$$F_x(\\infty)=1 \\implies \\sum_{i=-\\infty}^{+\\infty} p_X(x_i)=1$$\n",
    "\n",
    "$$P(x_{n_1} \\leq X \\leq x_{n_2}) = \\sum_{i=n_1}^{n_2} p_X(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Relación entre el histograma y la fdp\n",
    "\n",
    "Supongamos que tenemos una muestra estadística con $N$ observaciones de una variable estadística. Podemos considerar que tales observaciones corresponden a realizaciones de un experimento modelado por un espacio de probabilidad sobre el que hemos definido una variable aleatoria correspondiente con la variable estadística.\n",
    "\n",
    "El espacio de probabilidad propociona un modelo teórico de los datos, mientras que las muestra estadísitca resulta de la experiencia empírica. ¿Podemos caracterizar probabilísticamente la población a partir de la muetsra estadística?\n",
    "\n",
    "Como sabemos podemos construir un histograma de frecuencias relativas, sin más que agrupar los valores de la variable estadística por intervalos. Considerando que todos los intervalos tienen igual anchura $\\Delta x$, podemos aproximar la fdp en cada $x_i$ (puntos medios del intervalo, como sigue, siendo $F_i$ la frecuencia absoluta de observaciones que caen dentro del intervalo:\n",
    "\n",
    "$$f_X(x_i) \\approx \\frac{F_i}{N\\Delta x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esperanza matemática y momentos\n",
    "\n",
    "La esperanza matemática o media de una variable aleatoria $X$ es:\n",
    "\n",
    "$$\\eta_X = E\\{X\\}=\\int_{-\\infty}^{\\infty}xf_X(x)dx$$\n",
    "\n",
    "Si consideramos la aproximación anterior del histograma a la fdp, podemos ver que la media muestral aproxima la esperanza matemática: $\\hat x = \\sum_{i=1}^Nx_i\\frac{F_i}{\\Delta x} \\approx \\eta_X$.\n",
    "\n",
    "La esperanza matemática puede definirse sobre cualquier función $g(X)$ de la variable aleatoria:\n",
    "\n",
    "$$\\eta_{g(X)} = E\\{g(X)\\}=\\int_{-\\infty}^{\\infty}g(x)f_X(x)dx$$\n",
    "\n",
    "La **esperanza matemática es un operador lineal**, esto es, sean $g_1(X)$ y $g_2(X)$:\n",
    "$$E\\{a_1g_1(X)+a_2g_2(X)\\}=a_1E\\{g_1(X)\\}+a_2E\\{g_2(X)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos así definir los **momentos**:\n",
    "\n",
    "$$m_n=E\\{X^n\\}=\\int_{-\\infty}^{\\infty}x^nf_X(x)dx$$\n",
    "\n",
    "En particular, la **media** es $m_1\\equiv\\eta_X=E\\{X^1\\}$ y el **valor cuadrático medio** es $m_2=E\\{X^2\\}$\n",
    "\n",
    "Y los **momentos centrales**:\n",
    "\n",
    "$$\\mu_n=E\\{(X-\\eta_X)^n\\}=\\int_{-\\infty}^{\\infty}(x-\\eta_X)^nf_X(x)dx$$\n",
    "\n",
    "En particular, la **varianza** es $m_2\\equiv \\sigma_X^2 =E\\{(X-\\eta_X)^2\\}$. Aplicando la linealidad:\n",
    "\n",
    "$$\\sigma_X^2=E\\{(X-\\eta_X)^2\\}=E\\{X^2\\}-\\eta_X^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Esperanza y momentos en el caso discreto\n",
    "\n",
    "Si la **variable aleatoria es discreta**, se utilizan las funciones de masa de probabilidad en vez de las fdp, y sumas en vez de integrales:\n",
    "\n",
    "$$\\eta_{g(X)} = E\\{g(X)\\}=\\sum_{i=-\\infty}^{\\infty}g(x_i)p_X(x_i)$$\n",
    "\n",
    "$$m_n=E\\{X^n\\}=\\sum_{i=-\\infty}^{\\infty}x^nf_X(x)dx$$\n",
    "\n",
    "$$\\mu_n=E\\{(X-\\eta_X)^n\\}=\\sum_{i=-\\infty}^{\\infty}(x-\\eta_X)^nf_X(x)dx$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Todos estos momentos tienen sus equivalentes muestrales, ya vistos en la parte de introducción a la estadística. \n",
    "\n",
    "Por otra parte, es muy habitual **normalizar** una variable aleatoria $X$, construyendo otra $Y=\\frac{X-\\eta_X}{\\sigma_X}$ que tenga media nula y varianza unidad.\n",
    "\n",
    "Además, podemos definir:\n",
    "\n",
    "* Coeficiente de asimetría: $\\gamma_1=E\\{\\frac{(X-\\eta_X)^3}{\\sigma^3}\\}=\\frac{\\mu_3}{\\sigma_X^3}$ \n",
    "* Coeficiente de exceso de curtosis: $\\gamma_2=E\\{\\frac{(X-\\eta_X)^4}{\\sigma^4}\\}-3=\\frac{\\mu_4}{\\sigma_X^4}-3$. La distribución normal tiene un exceso de curtosis de 0, razón por la que se resta 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funciones condicionadas\n",
    "\n",
    "Consideremos un espacio de probabilidad $\\mathscr{E}$ en el que se ha definido una variable aleatoria $X$, su función de distribución $F_X(x)$ y su función de densidad $f_X(x)$. Considérese, además, un suceso $A \\in \\mathscr{F}$.\n",
    "\n",
    "La **función de distribución de $X$ condicionada por $A$** es: \n",
    "\n",
    "$$F_X(x\\, /\\, A) = P(X \\leq x \\, /\\, A) = \\frac{P(\\{X \\leq x \\bigcap A )\\} }{P(A)}$$\n",
    "\n",
    "Y la **función de densidad de $X$ condicionada por $A$** es:\n",
    "\n",
    "$$f_X(x \\, /\\, A)=\\frac{dF_X(x \\, /\\, A)}{dx}=\\lim \\limits_{\\Delta x \\to 0} \\frac{F_X(x+\\Delta x/2 \\, /\\, A)-F_X(x-\\Delta x/2 \\, /\\, A)}{\\Delta x}= \\\\\n",
    "=\\lim \\limits_{\\Delta x \\to 0} \\frac{P\\left(\\{(x-\\Delta x/2) < x \\leq (x+\\Delta x/2)\\} \\, /\\, A \\right)}{\\Delta x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En general el suceso condicionante $A$ podemos definirlo con intervalos de la variable aleatoria. Suponiendo que $A=\\{x_1\\leq X \\leq x_2\\}$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "F_X(x\\, /\\, \\{x_1\\leq X \\leq x_2\\}) & = \\frac{P(\\{X \\leq x \\bigcap \\{x_1\\leq X \\leq x_2\\ )\\} }{P(\\{x_1\\leq X \\leq x_2\\})}=\\\\\n",
    " & = \\begin{cases}\n",
    "    0       & \\quad x < x_1\\\\\n",
    "    \\frac{F_X(x)-F_X(x_1^-)}{F_X(x_2)-F_X(x_1^-)}  & \\quad x_1 \\leq x \\leq x_2\\\\\n",
    "    1 &\\quad x > x_2\n",
    "  \\end{cases}\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "f_X(x\\, /\\, \\{x_1\\leq X \\leq x_2\\}) = \\begin{cases}\n",
    "    0       & \\quad x < x_1\\\\\n",
    "    \\frac{f_X(x)}{F_X(x_2)-F_X(x_1^-)}  & \\quad x_1 \\leq x \\leq x_2\\\\\n",
    "    0 &\\quad x > x_2\n",
    "  \\end{cases}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Teorema de Bayes\n",
    "\n",
    "Recordemos el **Teorema de Bayes** con dos sucesos:\n",
    "\n",
    "$$P(A/B) = \\frac{P(B/A)P(A)}{P(B)}$$\n",
    "\n",
    "Si $B=\\{X \\leq x\\}$:\n",
    "\n",
    "$$P(A\\, / \\, X \\leq x) = \\frac{F_X(x \\, / \\, A)P(A)}{F_X(x)} \\iff F_X(x \\, / \\, A) = \\frac{P(A\\, / \\, X \\leq x)F_X(x)}{P(A)}$$\n",
    "\n",
    "Si $B=\\{x_1 < X \\leq x_2\\}$:\n",
    "\n",
    "$$P(A\\, / \\{x_1 < X \\leq x_2\\}) = \\frac{F_X(x_2 \\, / \\, A)-F_X(x_1 \\, / \\, A)}{F_X(x_2)-F_X(x_1)}P(A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si $B=\\{X=x\\}$ y la variable aleatoria es continua nos encontramos con un problema para condicionar por $B$ pues su probabilidad es nula. En tal caso consideramos que $B=\\{x<X-\\Delta x/2 \\leq x+\\Delta x/2\\}$ y tomamos un paso al límite:\n",
    "\n",
    "$$\\begin{align*}\n",
    "P(A \\, / \\, X=x) & = \\lim \\limits_{\\Delta x \\to 0} P(A\\, / \\{x-\\Delta x/2 < X \\leq x + \\Delta x/2\\}) \\\\\n",
    "& = \\lim \\limits_{\\Delta x \\to 0} \\frac{F_X(x +\\Delta x/2 \\, / \\, A)-F_X(x-\\Delta x/2 \\, / \\, A)}{F_X(x+\\Delta x/2)-F_X(x-\\Delta x/2)}P(A)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Por tanto,\n",
    "\n",
    "$$ P(A \\, / \\, X=x) = \\frac{f_X(x \\, / \\, A)P(A)}{f_X(x)} \\iff f_X(x \\, / \\, A) = \\frac{P(A \\, / \\, X=x)f_X(x)}{P(A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Teorema de la Probabilidad Total\n",
    "\n",
    "Sea $A_i \\in \\mathscr{P}(\\Omega) \\, i=1\\ldots K$ es una partición del espacio muestral $\\Omega$. Se obtiene inmediatamente el **Teorema de la Probabilidad Total**\n",
    "\n",
    "$$F_X(x) = F_X(x \\, / \\, A_1)P(A_1)+\\ldots + F_X(x \\, / \\, A_K)P(A_K)$$\n",
    "\n",
    "Derivando:\n",
    "\n",
    "$$f_X(x) = f_X(x \\, / \\, A_1)P(A_1)+\\ldots + f_X(x \\, / \\, A_K)P(A_K)$$\n",
    "\n",
    "Podemos obtener una versión continua del teorema integrando $f_X(x \\, / \\, A) = \\frac{P(A \\, / \\, X=x)f_X(x)}{P(A)}$:\n",
    "\n",
    "$$P(A) = \\int_{-\\infty}^{+\\infty} P(A \\, / \\, X=x)f_X(x) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Esperanza y momentos condicionados\n",
    "\n",
    "$$\\eta_{X/A} = E\\{X \\, / \\, A\\}=\\int_{-\\infty}^{\\infty}xf_X(x\\, / \\, A)dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
