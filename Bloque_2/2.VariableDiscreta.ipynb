{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.2 Variable Aleatoria Discreta\n",
    "\n",
    "Consideremos que la variable aleatoria $X$ sólo toma valores sobre un conjunto (finito o infinito) numerable de números. Los números Naturales, $\\mathbb{N}$, los números Enteros, $\\mathbb{Z}$, y los números Racionales, $\\mathbb{Q}$, son ejemplos de conjuntos infinitos numerables. Por su parte, los seis números de las caras de un dado constituyen un ejemplo de conjunto numerable finito. \n",
    "\n",
    "Consideremos que $x_i$ son los valores que puede tomar la variable aleatoria, donde $i\\in I$ se refiere a un índice numerable que recorre $I$ para poder indexar todos los valores. Por tanto $\\{X=x_i\\}$ se refiere a un suceso elemental cualquiera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los sucesos correspondientes a cada valor de una variable discreta pueden tener probabilidades arbitrarias, que interpretaremos con el símil mecánico de *masa*. Podemos entonces definir una **función de masa de probabilidad (fmp)** que asigna una masa de probabilidad a cada suceso elemental representado por un valor posible de la variable aleatoria discreta\n",
    "\n",
    "$$p_X(x_i)=P(\\{X=x_i\\})\\qquad i \\in I$$\n",
    "\n",
    "Considerando las propiedades de la probabilidad, se cumple:\n",
    "$$0\\leq p_X(x_i)\\leq 1 \\qquad \\forall i \\in I$$\n",
    "$$\\sum_{i \\in I} p_X(x_i)=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos un dado trucado, cuya función de masa de probabilidad se representa en la siguiente tabla:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccccc|c}\n",
    "  X & 1 & 2 & 3 & 4 & 5 & 6 &  \\\\ \n",
    "  \\hline\n",
    "  p_X(x_i) & \\frac{1}{24} & \\frac{5}{24} & \\frac{5}{24} & \\frac{3}{24} & \\frac{4}{24} & \\frac{6}{24} & \\sum_i p_X(x_i)=1\n",
    " \\end{array}\n",
    "$$\n",
    "\n",
    "Podemos fácilmente obtener las probabilidades de sucesos arbitrarios. Por ejemplo, la probabilidad de que salga $3$ ó $5$ es:\n",
    "$$\n",
    "P(X=\\{3,5\\})=P(\\{X=3\\}\\bigcup \\{X=5\\}) = p_X(3)+p_X(5)=\\frac{9}{24}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos ahora, sin pérdida de generalidad, que el índice que numera los posibles valores de la variable aleatoria $X$ es el conjunto de todos los números enteros $\\mathbb{Z}$, y que la ordenación es tal que $i<j \\iff x_i < x_j$. \n",
    "\n",
    "Definimos la **función acumulada de probabilidad (fap)**, $F_X(x_i)$, como sigue:\n",
    "\n",
    "$$F_X(x_i)=\\sum_{j=-\\infty}^{i}p_X(x_j)$$\n",
    "\n",
    "Adviértase que $F_X(-\\infty)=0$, $F_X(\\infty)=1$ y que $F_X(x_i)$ es una función *no decreciente* en toda subsucesión de puntos $x_i$.\n",
    "\n",
    "Por su parte, es fácil ver que $p_X(x_i)=F_X(x_i)-F_X(x_{i-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la FAP para nuestro dado trucado, representándola en una tabla junto con la fmp:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccccccc|c}\n",
    "  X & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & \\\\ \n",
    "  \\hline\n",
    "  p_X(x_i) & 0 & \\frac{1}{24} & \\frac{5}{24} & \\frac{5}{24} & \\frac{3}{24} & \\frac{4}{24} & \\frac{6}{24} & 0 & \\sum_i p_X(x_i)=1 \\\\\n",
    "  \\hline\n",
    "  F_X(x_i) & 0 & \\frac{1}{24} & \\frac{6}{24} & \\frac{11}{24} & \\frac{14}{24} & \\frac{18}{24} & \\frac{24}{24} & \\frac{24}{24} & \\begin{matrix}  \n",
    "  F_X(x_i\\leq 0)=0\\\\\n",
    "  F_X(x_i\\geq 6)=1 \n",
    " \\end{matrix}\n",
    " \\end{array}\n",
    "$$\n",
    "\n",
    "Donde, para completar la repesentación hemos añadido los valores $0$ y $7$ que, lógicamente, corresponden a sucesos imposibles (como cualquier otro valor distinto de los primeros seis números naturales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad condicionada\n",
    "\n",
    "Considérese un suceso $M$, de probabilidad $P(M)$, del espacio muestral sobre el que se ha definido la variable aleatoria discreta $X$. Definimos la función de masa de probabilidad de $X$ condicionada por $M$ como sigue:\n",
    "\n",
    "$$p_X(x_i/M) = \\frac{P(\\{X=x_i\\}\\bigcap M)}{P(M)} $$\n",
    "\n",
    "Adviértase que $\\sum_i p_X(x_i/M) =1$\n",
    "\n",
    "Frecuentemente $M$ podrá expresarse por medio de la variable aleatoria $X$, lo que simplifica el cálculo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos los sucesos *Par* e *Impar* en el dado trucado que ya hemos visto y calculemos las funciones de masa de probabilidad condicionadas $p_X(x_i/Par)$ y $p_X(x_i/Impar)$\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccccc|c}\n",
    "  X & 1 & 2 & 3 & 4 & 5 & 6 &  \\\\ \n",
    "  \\hline\n",
    "  p_X(x_i) & \\frac{1}{24} & \\frac{5}{24} & \\frac{5}{24} & \\frac{3}{24} & \\frac{4}{24} & \\frac{6}{24} & \\sum_i p_X(x_i)=1 \\\\\n",
    "  \\hline\n",
    "  P(Impar) & \\frac{1}{24} & + & \\frac{5}{24} & + & \\frac{4}{24} &  & P(Impar) = \\frac{10}{24} \\\\\n",
    "  P(Par)  &  & \\frac{5}{24} & + & \\frac{3}{24} & + & \\frac{6}{24} & P(Par) = \\frac{14}{24}\\\\\n",
    "  \\hline\n",
    "  p_X(x_i/Impar) & \\frac{1}{10} & 0 & \\frac{5}{10} & 0 & \\frac{4}{10} & 0 & \\sum_i p_X(x_i/Impar)=1 \\\\\n",
    "  p_X(x_i/Par) & 0 & \\frac{5}{14} & 0 & \\frac{3}{14} & 0 & \\frac{6}{14} & \\sum_i p_X(x_i/Par)=1\n",
    " \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también definir la probabilidad de un suceso $M$ condicionada por un valor arbitrario $x_i$ de la variable aleatoria $X$. Para ello no hay más que advertir que $\\{X=x_i\\}$ es un suceso del espacio muestral:\n",
    "\n",
    "$$P(M/X=x_i)= \\frac{P(M \\bigcap \\{X=x_i\\})}{P(\\{X=x_i\\})}=\\frac{P(M \\bigcap \\{X=x_i\\})}{p_X(x_i)}$$\n",
    "\n",
    "Haremos uso frecuente del abuso de notación $P(M/x_i)\\equiv P(M/X=x_i)$.\n",
    "\n",
    "Adviértase que $P(M/x_i) \\neq p_X(x_i/M)$, estando ambas expresiones relacionadas mediante el Teorema de Bayes, como se verá más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de la Probabilidad Total\n",
    "\n",
    "Consideremos una partición del espacio muestral \n",
    "$$\n",
    "M_j \\in \\mathscr{P}(\\Omega) \\, j=1\\ldots N\\iff  \\begin{matrix}\n",
    "  \\bigcup_{j=1}^N M_j = \\Omega &  \\\\\n",
    "  M_j \\cap M_k = \\emptyset & j\\neq k  \n",
    " \\end{matrix}\n",
    "$$\n",
    " \n",
    "y que conocemos las funciones de masa de probabilidad de una variable aleatoria $X$ definida en el mismo condicionadas por todos los sucesos de dicha partición $p_X(x_i/M_j)$, así como las probabilidades de todos los sucesos condicionantes. \n",
    "\n",
    "La función de masa de probabilidad total (sin condicionar) de la variable aleatoria $X$ es\n",
    "\n",
    "$$p_X(x_i) = \\sum_{j=1}^N p_X(x_i/M_j)P(M_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adviértase que el teorema permite descomponer una función de masa de probabilidad en *mezcla* (*mixture*) de funciones de masa de probabilidad condicionadas, algo que resulta con frecuencia útil. \n",
    "\n",
    "En el caso de tener un único suceso $M$, consideramos que el espacio muestral se particiona con él y con su suceso complementario $\\overline M$, y que $P(\\overline M)=1-P(M)$, resultando:\n",
    "\n",
    "$$p_X(x_i)=p_X(x_i/M)P(M)+p_X(x_i/\\overline M)(1-P(M))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad total también puede aplicarse de forma alternativa, si lo que se conocen son las probabilidades un suceso arbitrario $M$ condicionadas por cada uno de los valores posibles de la variable aleatoria $X$, esto es, si se conocen $P(M/x_i)\\equiv P(M/X=x_i)$. \n",
    "\n",
    "En tal caso, la probabilidad total del suceso $M$ (sin condicionar) es\n",
    "\n",
    "$$P(M) = \\sum_{i=-\\infty}^\\infty P(M/x_i) p_X(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de Bayes\n",
    "\n",
    "Partiendo de la definición de función de masa de probabilidad condicionada es inmediato obtener el **Teorema de Bayes** (recordar que $P(M/x_i)\\equiv P(M/X=x_i)$):\n",
    "\n",
    "$$p_X(x_i/M) = \\frac{P(M/x_i)p_X(x_i)}{P(M)} \\iff P(M/x_i) = \\frac{p_X(x_i/M)P(M)}{p(x_i)}$$\n",
    "\n",
    "Con frecuencia, los denominadores de las expresiones anteriores se obtienen mediante el *Teorema de la Probabilidad Total*, pues tan sólo se conocen las probabilidades condicionadas:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p_X(x_i/M) &= \\frac{P(M/x_i)p_X(x_i)}{\\sum_{i=-\\infty}^\\infty P(M/x_i) p_X(x_i)} \\\\ \n",
    "P(M/x_i) &= \\frac{p_X(x_i/M)P(M)}{p_X(x_i/M)P(M)+p_X(x_i/\\overline M)(1-P(M))}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos el Teorema de Bayes al ejemplo del dado trucado para obtener, trivialmente, las probabilidades de los sucesos *Par* e *Impar* condicionadas por los valores de la variable aleatoria:\n",
    "$$\n",
    "\\begin{array}{c|cccccc|c}\n",
    "  X & 1 & 2 & 3 & 4 & 5 & 6 &  \\\\ \n",
    "  \\hline\n",
    "  p_X(x_i) & \\frac{1}{24} & \\frac{5}{24} & \\frac{5}{24} & \\frac{3}{24} & \\frac{4}{24} & \\frac{6}{24} & \\sum_i p_X(x_i)=1 \\\\\n",
    "  \\hline\n",
    "  P(Impar) & \\frac{1}{24} & + & \\frac{5}{24} & + & \\frac{4}{24} &  & P(Impar) = \\frac{10}{24} \\\\\n",
    "  P(Par)  &  & \\frac{5}{24} & + & \\frac{3}{24} & + & \\frac{6}{24} & P(Par) = \\frac{14}{24}\\\\\n",
    "  \\hline\n",
    "  p_X(x_i/Impar) & \\frac{1}{10} & 0 & \\frac{5}{10} & 0 & \\frac{4}{10} & 0 & \\sum_i p_X(x_i/Impar)=1 \\\\\n",
    "  p_X(x_i/Par) & 0 & \\frac{5}{14} & 0 & \\frac{3}{14} & 0 & \\frac{6}{14} & \\sum_i p_X(x_i/Par)=1\\\\\n",
    "  \\hline\n",
    "  P(Impar/x_i) & 1 & 0 & 1 & 0 & 1 & 0 & \\sum_i p_X(Impar/x_i)\\neq 1\\\\\n",
    "  P(Par/x_i) & 0 & 1 & 0 & 1 & 0 & 1 & \\sum_i p_X(Par/x_i)\\neq 1\n",
    " \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de variable aleatoria\n",
    "\n",
    "Consideremos una variable aleatoria discreta $X$. Podemos aplicar sobre la misma una función $g$ que devolverá valores aleatorios, al serlo también su variable independiente. Lo representamos como sigue:\n",
    "\n",
    "$$Y = g(X)$$\n",
    "\n",
    "Cada valor $x_i$ de $X$ se transformará por la función en un nuevo valor $y_i$ de $Y$. Adviértase que valores distintos $x_i \\neq x_j$ pueden dar lugar a valores iguales $y_i = y_j$ con tal que $g(x_i)=g(x_j)$. Por tanto, definimos la función de masa de probabilidad de $Y$ como sigue:\n",
    "\n",
    "$$p_Y(y_i) = \\sum_j p_X(g^{-1}(y_i))\n",
    "= \\sum_{\\substack{j \\\\ g(x_j) = y_i}}p_X(x_j)$$\n",
    "\n",
    "Donde $j$ indexa las raíces de la ecuación $y_i=g(x_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos, por ejemplo, la variable aleatoria $X$ con la siguiente fmp:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccc|c}\n",
    "X & -2 & -1 & 0 & 1\\\\\n",
    "\\hline\n",
    "p_X(x_i) & \\frac{1}{8} & \\frac{1}{8} & \\frac{1}{2} & \\frac{1}{4} & \\sum_i p_X(x_i) = 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Veamos cuál es la fmp de la variable aleatoria $Y = X^2$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc|c}\n",
    "Y & 0 & 1 & 4\\\\\n",
    "\\hline\n",
    "p_Y(y_i) & \\frac{1}{2} & \\frac{1}{4}+\\frac{1}{8} & \\frac{1}{8} & \\sum_i p_Y(y_i) = 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Si se desean incluir otros valores de $Y$ en la representación, por ejemplo el $2$ ó el $3$, tendrán masa de probabilidad nulas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esperanza Matemática y Valor Medio. Momentos\n",
    "\n",
    "Se define la esperanza matemática de una función $g(X)$ de una variable aleatoria como sigue:\n",
    "\n",
    "$$E(g(X))=\\sum_i g(x_i)p_X(x_i)$$\n",
    "\n",
    "Es fácil advertir que el operador $E(·)$ es lineal, esto es que\n",
    "\n",
    "$$E(a_1g_1(X)+a_2g_2(X))=a_1E(g_1(X)) + a_2E(g_2(X))$$\n",
    "\n",
    "donde $a_1$ y $a_2$ son coeficiente constantes arbitrarios y $g_1$ y $g_2$ son dos funciones. También es evidente que, si $k$ es una constante arbitraria\n",
    "\n",
    "$$E(k) = k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $g$ es la función identidad obtenemos el **valor medio** de la variable aleatoria $X$:\n",
    "$$\\eta_X=E(X)=\\sum_i x_ip_X(x_i)$$\n",
    "\n",
    "Es conveniente **reflexionar sobre la relación con la media muestral**, advirtiendo que ambas son medidas de tendencia central.\n",
    "\n",
    "Adviértase que, como una función de variable aleatoria define una nueva variable aleatoria, $Y=g(X)$, con su propia función de masa de probabilidad, tenemos dos maneras de calcular la esperanza de una función de variable aleatoria:\n",
    "\n",
    "$$\\eta_Y = E(Y)=\\sum_i y_ip_Y(y_i) = \\sum_i g(x_i)p_X(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos que la variable aleatoria $X$ tiene valor medio $\\eta_X$. Calculemos cuál sera el valor medio de la variable aleatoria $Y = aX+b$, donde $a$ y $b$ son coeficientes constantes.\n",
    "\n",
    "Aplicando linealidad:\n",
    "\n",
    "$$E(aX+b) = aE(X)+b = a\\eta_X + b$$\n",
    "\n",
    "Son interesantes los casos particulares:\n",
    "* Sumar constante, $a=1$: $E(X+b) = \\eta_X + b$\n",
    "* Multiplicar por constante $a$, $b=0$: $E(aX) = a\\eta_X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentos de Segundo Orden: Valor Cuadrático Medio y Varianza\n",
    "\n",
    "El **valor cuadrático medio**, o momento no centrado de segundo orden, de la variable aleatoria $X$ se define:\n",
    "$$E(X^2)=\\sum_i x_i^2p_X(x_i) \\geq 0$$\n",
    "\n",
    "El valor cuadrático medio es una medida de dispersión respecto del origen, a la que no afecta el signo positivo o negativo de las excursiones (al estar elevada al cuadrado) sino solo la amplitud de las mismas. Por ello siempre es una magnitud positiva, salvo en el caso trivial de que toda la masa de probabilidad se localice en el origen (el valor es determinista e igual a cero).\n",
    "\n",
    "Es conveniente reflexionar sobre su relación con el estadístico muestral correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos que la variable aleatoria $X$ tiene valor medio $\\eta_X$ y valor cuadrático medio $E(X^2)$. Calculemos cuál sera el valor cuadrático medio de la variable aleatoria $Y = aX+b$, donde $a$ y $b$ son coeficientes constantes.\n",
    "\n",
    "Desarrollando el cuadrado y aplicando linealidad:\n",
    "\n",
    "$$E((aX+b)^2) = a^2E(X^2)+(2ab\\eta_X+b^2)$$\n",
    "\n",
    "Es interesante el caso de multiplicar por una constante $a$, $b=0$:\n",
    "$$E((aX)^2) = a^2E(X^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **varianza** o momento centrado de segundo orden, se define:\n",
    "$$\\sigma_X^2 \\equiv Var(X) = E((X-\\eta_X)^2) \\geq 0$$\n",
    "\n",
    "La varianza es una medida de dispersión de los valores de la variable aleatoria en relación a su valor medio. De nuevo, al estar elevada al cuadrado, no importa el signo de las excursiones, sino sólo su amplitud y, por ello, siempre es una magnitud positiva, o trivialmente nula si toda la masa de probabilidad está localizada en el mismo punto (valor determinista).\n",
    "\n",
    "La raíz cuadrada de la varianza se denomina **desviación típica**, $\\sigma_X$.\n",
    "\n",
    "Desarrollando la definición y aplicando la propiedad de linealidad, se obtiene:\n",
    "$$\\sigma_X^2 = E(X^2) - \\eta_X^2 \\implies E(X^2) \\geq \\sigma_X^2$$\n",
    "\n",
    "Si la variable aleatoria tiene **media nula**: $E(X^2) = \\sigma_X^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos ahora que la variable aleatoria $X$ tiene valor medio $\\eta_X$, valor cuadrático medio $E(X^2)$ y varianza $\\sigma_X^2\\equiv Var(X)$. Calculemos cuál sera la varianza de la variable aleatoria $Y = aX+b$, donde $a$ y $b$ son coeficientes constantes.\n",
    "\n",
    "Aplicando la relación entre valor cuadrático medio, varianza y cuadrado de la media:\n",
    "\n",
    "$$Var(aX+b) = E((aX+b)^2)-E^2(aX+b)$$\n",
    "\n",
    "Utilizando las expresiones que ya tenemos:\n",
    "\n",
    "$$\\begin{align*}\n",
    "E((aX+b)^2) &= a^2E(X^2)+2ab\\eta_X+b^2\\\\\n",
    "E^2(aX+b) &= (a\\eta_X+b)^2 = a^2\\eta_X^2+2ab\\eta_X+b^2\n",
    "\\end{align*}$$ \n",
    "\n",
    "Resultando la varianza:\n",
    "$$\\begin{align*}\n",
    "Var(aX+b) &= a^2E(X^2)-a^2\\eta_X^2=a^2(E(X^2)-\\eta_X^2)\\\\\n",
    "&=a^2Var(X)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipificación de una Variable Aleatoria\n",
    "\n",
    "Consideremos que una variable aleatoria $X$ tiene valor medio $\\eta_X$ y varianza $\\sigma_X$. **Tipificar** la variable quiere decir buscar otra equivalente, pero con **media nula** y **varianza unidad**.\n",
    "\n",
    "La variable tipificada $\\hat X$ la obtenemos aplicando la siguiente función:\n",
    "\n",
    "$$\\hat X = \\frac{X-\\eta_X}{\\sigma_X}$$\n",
    "\n",
    "De lo visto anteriormente, es inmediato advertir que:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\eta_{\\hat X}= E(\\hat X) &= \\frac{1}{\\sigma_X}\\eta_X-\\frac{\\eta_X}{\\sigma_X}&=0 \\\\\n",
    "\\sigma_{\\hat X}^2 = Var(\\hat X) &=\\frac{1}{\\sigma_X^2}\\sigma_X^2 &= 1 \n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentos de orden superior\n",
    "\n",
    "El momento no centrado de orden $n$ se define como:\n",
    "\n",
    "$$m_n =E(X^n)=\\sum_i x_i^np_X(x_i)$$\n",
    "\n",
    "El momento centrado de orden $n$:\n",
    "$$\\mu_n =E((X-\\eta_X)^n)=\\sum_i (x_i-\\eta_X)^np_X(x_i)$$\n",
    "\n",
    "Y el momento tipificado de orden $n$:\n",
    "$$\\gamma_n =E(\\left(\\frac{X-\\eta_X}{\\sigma_X}\\right)^n)=\\sum_i \\left(\\frac{x_i-\\eta_X}{\\sigma_X}\\right)^np_X(x_i)$$\n",
    "\n",
    "El momento tipificado de orden 3 corresponde al coeficiente de asimetría, y el de orden 4 al coeficiente de curtosis. Es conveniente reflexionar sobre su relación con sus equivalentes muestrales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esperanza Matemática Condicionada\n",
    "\n",
    "Podemos definir la esperanza matemática de una función $g$ de la variable aleatoria $X$ condicionada por el suceso $M$ como sigue:\n",
    "\n",
    "$$E(g(X)/M)=\\sum_i g(x_i)p_X(x_i/M)$$\n",
    "\n",
    "Podemos extender con la esperanza condicionada las propiedades y definiciones vistas anteriormente. Por ejemplo:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\eta_{X/M}=E(X/M)&=\\sum_i x_ip_X(x_i/M)\\\\\n",
    "E(X^2/M)&=\\sum_i x_i^2p_X(x_i/M)\\\\\n",
    "\\sigma_{X/M}^2 = Var(X/M) &= \\sum_i (x_i-\\eta_{X/M})^2p_X(x_i/M) = E(X^2/M)-\\eta_{X/M}^2\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuciones de Masa de Probabilidad Habituales\n",
    "\n",
    "## La Distribución de Bernoulli\n",
    "\n",
    "Está asociada a la ocurrencia de un evento $A$ con probabilidad $p=P(A)$, construyéndose la variable aleatoria $X$ asignando el valor $1$ cuando $A$ acontece y $0$ cuando no lo hace. Por tanto, la función de masa de probailidad es:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc|c}\n",
    "X & 0 & 1\\\\\n",
    "\\hline\n",
    "p_X(x_i) & q=1-p & p=P(A) & \\sum_i p_X(x_i) = 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Podemos dar una forma funcional, haciendo además explícita en la definición la dependencia con el parámetro $p$:\n",
    "\n",
    "$$Bernoulli(p) \\equiv p_X(x_i;p)=p^{x_i}(1-p)^{1-x_i} \\qquad x_i \\in \\{0,1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular fácilmente los principales estadísticos de la distribución:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\eta_X = E(X) &= 0(1-p)+1p &= p\\\\\n",
    "E(X^2) &= 0^2(1-p)+1^2p &= p\\\\\n",
    "\\sigma_X^2=Var(X) &= E(X^2)-\\eta_X^2 = p-p^2 &= p(1-p)\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Distribución Binomial\n",
    "\n",
    "Consideremos la repetición de $n$ experimentos de Bernoulli independientes. La distribución binomial modela la probabilidad de que el suceso $A$ acontezca $x_i$ veces en los $n$ intentos:\n",
    "\n",
    "$$B(n,p)\\equiv p_X(x_i; n,p) = \\binom{n}{x_i}p^{x_i}(1-p)^{n-x_i} \\qquad n \\in \\mathbb{N} \\quad x_i \\in \\{0,1 \\ldots n\\}$$\n",
    "\n",
    "Considerando que una variable aleatoria binomial puede considerarse suma de $n$ variables de Bernoulli independientes, se demuestra (se verá cuando se vean varias variables aleatorias conjuntas) que la media y la varianza son:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\eta_X = E(X) &= np\\\\\n",
    "\\sigma_X^2=Var(X) &= np(1-p)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Distribución Poisson\n",
    "\n",
    "La función de masa de probabilidad de la distribución de Poisson es:\n",
    "\n",
    "$$Pois(\\lambda)\\equiv p_X(x_i;\\lambda) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$$\n",
    "\n",
    "Esta distribución surge cuando se hacen crecer el número de repeticiones de una distribución Binomial, de modo que la probabilidad de éxito se hace muy pequeña pero el producto de tal probabilidad y el número de repeticiones se mantiene constante:\n",
    "\n",
    "$$n \\rightarrow \\infty \\begin{cases}\n",
    "    p \\rightarrow 0\\\\\n",
    "    np \\rightarrow \\lambda\n",
    "  \\end{cases} \\implies B(n,p) \\rightarrow Pois(\\lambda)$$\n",
    "  \n",
    "El valor medio y la varianza resultan ser: $\\eta_X=\\sigma_X^2=\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los **procesos puntuales de Poisson** son importantes en la práctica. Considérese un intervalo de longitud $\\Delta$ en el que se resaltan puntos de forma totalmente aleatoria con una densidad o tasa de llegada de $r$. El promedio de puntos que surgirán en el mismo es $\\lambda = r\\Delta$. El intervalo podría ser también una porción del plano o del espacio, con una interpretación semejante para los puntos.\n",
    "* El número de puntos en dos subintervalos disjuntos es independiente, por la aleatoriedad en su surgimiento o llegada.\n",
    "* El número de puntos del intervalo tiene una distribución $Pois(r\\Delta)$\n",
    "* Como se verá más adelante, si el intervalo es lineal, el periodo de espera hasta el siguiente punto sigue una distribución exponencial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones Multinoulli y Uniforme\n",
    "\n",
    "Se trata de la distribución genérica de una variable aleatoria discreta que puede tomar $N$ valores posibles. Un ejemplo es el dado trucado visto anteriormente, en el que $N=6$ y cada cara tiene una probabilidad $p_X(x_i)$, con $x_i \\in \\{1, \\ldots 6\\}$.\n",
    "\n",
    "* Un caso particular es cuando $N=2$, $x_i \\in \\{0,1\\}$, que corresponde a la distribución de Bernoulli.\n",
    "* La **distribución uniforme** es el caso particular en que la variable aleatoria toma valores entre $a$ y $b$, todos con igual probabilidad.  Esto es:\n",
    "\n",
    "$$U(a,b)\\equiv p_X(x_i;a,b)=1/N \\qquad a < b \\in \\mathbb{Z} \\qquad N=b-a+1$$  \n",
    "\n",
    "$$\\eta_X = \\frac{a+b}{2}$$\n",
    "$$\\sigma_X^2 = \\frac{(b-a+1)^2-1}{12}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
