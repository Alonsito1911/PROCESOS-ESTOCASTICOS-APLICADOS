{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variables Aleatorias N-Dimensionales\n",
    "\n",
    "Al introducir el concepto de variable aleatoria conjunta, ya se mencionó que los vectores aleatorios pueden tener un número arbitrario $M$ de componentes:\n",
    "\n",
    "$$\\mathbf X = (X_1, \\ldots X_M)^\\mathrm{T}$$\n",
    "\n",
    "Ya hemos visto en profundidad la caracterización conjunta y marginal para el caso de dos variables aleatorias (vector aleatorio de dimesión $2$). La extensión a $M$ componentes es inmediata:\n",
    "\n",
    "La **Función de Distribución Conjunta** $F_\\mathbf{X}(\\mathbf{x}) \\equiv F_{X_1\\ldots X_M}(x_1,\\ldots x_M)$ es\n",
    "\n",
    "$$\n",
    "F_\\mathbf{X}(\\mathbf{x}) \\equiv F_{X_1\\ldots X_M}(x_1,\\ldots x_M) = \n",
    "P(X_1 \\leq x_1, \\ldots X_M \\leq x_M)\n",
    "$$\n",
    "\n",
    "Las **funciones de distribución marginales** se obtienen sin más que evaluar en $\\infty$ las variables que se desean descartar. Por ejemplo:\n",
    "\n",
    "$$\n",
    "F_{X_1X_3}(x_1, x_3) = F_{X_1\\ldots X_N}(x_1,\\infty, x_3, \\infty , \\ldots \\infty)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "F_{X_3}(x_3) = F_{X_1 \\ldots X_N}(\\infty,\\infty, x_3, \\infty , \\ldots \\infty)\n",
    "$$\n",
    "\n",
    "Por supuesto, $F_\\mathbf{X}(\\boldsymbol{\\infty}) \\equiv F_{X_1\\ldots X_M}(\\infty,\\ldots \\infty) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suele resultar oportuno definir el vector aleatorio $\\mathbf{V}$ con dos componentes que son, a su vez, vectores aleatorios, $\\mathbf X = (X_1, \\ldots X_M)^\\mathrm{T}$ e $\\mathbf X = (X_1, \\ldots X_M)^\\mathrm{T}$:\n",
    "\n",
    "$$\\mathbf V = (\\mathbf{X}^\\mathrm{T} , \\mathbf{Y}^\\mathrm{T})^\\mathrm{T} = \n",
    "(X_1, \\ldots X_M , Y_1 \\ldots Y_M)^\\mathrm{T}$$\n",
    "\n",
    "Ello permite aplicar de forma prácticamente directa las expresiones vistas para la caracterización del vector bidimensional $(X,Y)$ al vector $M+N$-dimensional $\\mathbf V = (\\mathbf{X}^\\mathrm{T} , \\mathbf{Y}^\\mathrm{T})^\\mathrm{T}$, recurriendo a ciertos *abusos de notación* muy sencillos de entender. Por ejemplo:\n",
    "\n",
    "$$\n",
    "F_\\mathbf{V}(\\mathbf{v}) \\equiv F_{\\mathbf{X},\\mathbf{Y}}(\\mathbf{x},\\mathbf{y}) = \n",
    "P(X_1 \\leq x_1, \\ldots X_M \\leq x_M, Y_1 \\leq y_1 \\ldots Y_M \\leq y_M) \\equiv \n",
    "P(\\mathbf{X} \\leq \\mathbf{x}, \\mathbf{Y} \\leq \\mathbf{y})\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{\\mathbf{X}}(\\mathbf{x}) = F_{\\mathbf{X}\\mathbf{Y}}(\\mathbf{x},\\boldsymbol{\\infty}) \\equiv\n",
    "F_{X_1\\ldots X_M Y_1 \\ldots Y_N}(x_1,\\ldots x_M , \\infty , \\ldots \\infty) = F_{X_1\\ldots X_M}(x_1,\\ldots x_M)\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{\\mathbf{Y}}(\\mathbf{y}) = F_{\\mathbf{X}\\mathbf{Y}}(\\mathbf{\\boldsymbol{\\infty}},\\mathbf{y}) \\equiv\n",
    "F_{X_1\\ldots X_M Y_1 \\ldots Y_N}(\\infty,\\ldots \\infty , y_1 , \\ldots y_N) = F_{Y_1\\ldots Y_N}(y_1,\\ldots y_N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Función de densidad conjunta multidimensional\n",
    "\n",
    "La **función de densidad conjunta** del vector aleatorio $\\mathbf X$, suponiendo que está compuesto por **variables aleatorias continuas**, es:\n",
    "\n",
    "$$\n",
    "f_\\mathbf{X}(\\mathbf{x}) \\equiv f_{X_1\\ldots X_M}(x_1,\\ldots x_M) = \\frac{\\partial^{M} F_{X_1 \\ldots X_M}\\left(x_{1}, \\ldots, x_{M}\\right)}{\\partial x_{1}, \\ldots, \\partial x_{M}} \\equiv\n",
    "\\frac{\\boldsymbol{\\partial} F_\\mathbf{X}(\\mathbf{x})}{\\boldsymbol{\\partial} \\mathbf{x}}\n",
    "$$\n",
    "\n",
    "Por tanto, puede obtenerse la función de distribución a partir de la de densidad conjunta:\n",
    "\n",
    "$$\n",
    "F_\\mathbf{X}(\\mathbf{x}) \\equiv F_{X_1\\ldots X_M}(x_1,\\ldots x_M) = \\int_{-\\infty}^{x_1} \\ldots \\int_{-\\infty}^{x_M} f_{X_1\\ldots X_M}(x_1,\\ldots x_M) dx_1 \\ldots dx_M \\equiv \n",
    "\\boldsymbol{\\int}_{\\boldsymbol{-\\infty}}^{\\mathbf{x}} f_\\mathbf{X}(\\mathbf{x})\\mathbf{dx} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**La masa total de probabilidad es uno**:\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} \\ldots \\int_{-\\infty}^{\\infty} f_{X_1\\ldots X_M}(x_1,\\ldots x_M) dx_1 \\ldots dx_M = F_{X_1 \\ldots X_M}(\\infty,\\ldots \\infty) = 1 \\equiv \\\\\n",
    "\\equiv \\boldsymbol{\\int}_{\\boldsymbol{-\\infty}}^{\\boldsymbol{\\infty}} f_\\mathbf{X}(\\mathbf{x})\\mathbf{dx}\n",
    "= F_\\mathbf{X}(\\boldsymbol{\\infty}) = 1\n",
    "$$\n",
    "\n",
    "Las **funciones de densidad marginales** se obtienen sin más que integrar las variables que se desean descartar. Por ejemplo:\n",
    "\n",
    "$$\n",
    "f_{X_1X_3}(x_1,x_3) = \\int_{-\\infty}^{\\infty}\\ldots \\int_{-\\infty}^{\\infty} f_{X_1\\ldots X_M} (x_1, \\ldots x_M) dx_2 dx_4 \\ldots dx_M\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_{X_1}(x_1) = \\int_{-\\infty}^{\\infty}\\ldots \\int_{-\\infty}^{\\infty} f_{X_1\\ldots X_M} (x_1, \\ldots x_M) dx_2 \\ldots dx_M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Considerando ahora el vector aleatorio $\\mathbf{V}$ definido como antes:\n",
    "\n",
    "$$\n",
    "f_{\\mathbf{V}}(\\mathbf{v}) \\equiv f_\\mathbf{XY}(\\mathbf{x},\\mathbf{y}) = \n",
    "\\frac{\\boldsymbol{\\partial}^2 F_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y})}{\\boldsymbol{\\partial} \\mathbf{x}\\boldsymbol{\\partial} \\mathbf{y}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_\\mathbf{V}(\\mathbf{v}) \\equiv F_{\\mathbf{X} \\mathbf{Y}}(\\mathbf{x},\\mathbf{y}) = \\int_{-\\boldsymbol{\\infty}}^{\\mathbf{x}}\\int_{-\\boldsymbol{\\infty}}^{\\mathbf{y}} f_{\\mathbf{X}\\mathbf{Y}}(\\mathbf{x},\\mathbf{y}) \\mathbf{dx dy} \\equiv \n",
    "\\boldsymbol{\\int}_{\\boldsymbol{-\\infty}}^{\\mathbf{v}} f_\\mathbf{V}(\\mathbf{v})\\mathbf{dv} \n",
    "$$\n",
    "\n",
    "Y las funciones de densidad marginales de ambos vectores componentes son:\n",
    "\n",
    "$$\n",
    "f_{\\mathbf{X}}(\\mathbf{x}) = \\boldsymbol{\\int}_{-\\boldsymbol{\\infty}}^{\\boldsymbol{\\infty}} f_{\\mathbf{XY}}(\\mathbf{x}, \\mathbf{y}) \\mathbf{dy}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_{\\mathbf{Y}}(\\mathbf{y}) = \\boldsymbol{\\int}_{-\\boldsymbol{\\infty}}^{\\boldsymbol{\\infty}} f_{\\mathbf{XY}}(\\mathbf{x}, \\mathbf{y}) \\mathbf{dx}\n",
    "$$\n",
    "\n",
    "Por supuesto, $\n",
    "\\int_{-\\boldsymbol{\\infty}}^{\\boldsymbol{\\infty}}\\int_{-\\boldsymbol{\\infty}}^{\\boldsymbol{\\infty}} f_{\\mathbf{X}\\mathbf{Y}}(\\mathbf{x},\\mathbf{y}) \\mathbf{dx dy} = F_{\\mathbf{X} \\mathbf{Y}}(\\infty,\\infty) = 1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Como ya sabemos, las funciones marginales no permiten conocer la conjunta salvo que sean independientes. La **independencia conjunta** requiere que todas las combinaciones posibles de variables aleatorias componentes sean independientes. En tal caso:\n",
    "\n",
    "$$\n",
    "F_{X_1 \\ldots X_M}(x_1 \\ldots x_M) = F_{X_1}(x_1) \\ldots F_{X_M}(x_M)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_{X_1 \\ldots X_M}(x_1 \\ldots x_M) = f_{X_1}(x_1) \\ldots f_{X_M}(x_M)\n",
    "$$\n",
    "\n",
    "En el caso de que tengamos dos vectores aleatorios $\\mathbf{X}$, $\\mathbf{Y}$ independientes entre sí (pero no necesariamente las componentes de cada uno de ellos por separado):\n",
    "\n",
    "$$\n",
    "F_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y}) = F_{\\mathbf{X}}(\\mathbf{x}) F_{\\mathbf{Y}}(\\mathbf{y})\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y}) = f_{\\mathbf{X}}(\\mathbf{x}) f_{\\mathbf{Y}}(\\mathbf{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Función de masa de probabilidad conjunta\n",
    "\n",
    "Si las componentes del vector aleatorio son **variables aleatorias discretas**, la función de distribución resulta discontinua y no es derivable. Como ya hemos visto, en tal caso recurrimos a la **función de masa de probabilidad conjunta**\n",
    "\n",
    "$$\n",
    "p_{\\mathbf{X}}(\\mathbf{x_i}) \\equiv p_{X_1 \\ldots X_M}(x_{i_1}, \\ldots x_{i_M}) = P(X_1 = x_{i_1} , \\ldots X_M = x_{i_M})\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_{\\mathbf{V}}(\\mathbf{v_{k}}) \\equiv p_{\\mathbf{X} \\mathbf{Y}}(\\mathbf{x_{i}}, \\mathbf{y_{j}}) = P(\\mathbf{X} = \\mathbf{x_{i}} , \\mathbf{Y} = \\mathbf{y_{j}})\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{i} =(i_1 \\ldots i_M)$, $\\mathbf{j} =(j_1 \\ldots j_N)$ y $\\mathbf{k}$ es la concatenación de ambos. La **función de distribución conjunta** se obtiene acumulando la función de masa de probabilidad conjunta:\n",
    "\n",
    "$$\n",
    "F_\\mathbf{X}(\\mathbf{x_i}) \\equiv F_{X_1\\ldots X_M}(x_{i_1},\\ldots x_{i_M}) = \\sum_{p_1=-\\infty}^{i_1} \\ldots \\sum_{p_M=-\\infty}^{i_M} f_{X_1\\ldots X_M}(x_{p_1},\\ldots x_{p_M}) \\equiv \n",
    "\\boldsymbol{\\sum}_{\\mathbf{p}=\\boldsymbol{-\\infty}}^{\\mathbf{i}} f_\\mathbf{X}(\\mathbf{x_p}) \n",
    "$$\n",
    "\n",
    "$$\n",
    "F_\\mathbf{V}(\\mathbf{v_k}) \\equiv F_{\\mathbf{X} \\mathbf{Y}}(\\mathbf{x_i},\\mathbf{y_j}) = \\sum_{\\mathbf{p}=-\\boldsymbol{\\infty}}^{\\mathbf{i}}\\sum_{\\mathbf{q}=-\\boldsymbol{\\infty}}^{\\mathbf{j}} p_{\\mathbf{X}\\mathbf{Y}}(\\mathbf{x_p},\\mathbf{y_q}) \\equiv \n",
    "\\boldsymbol{\\sum}_{\\mathbf{r}=\\boldsymbol{-\\infty}}^{\\mathbf{k}} f_\\mathbf{V}(\\mathbf{v_r}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Momentos conjuntos: Vector de medias y matrices de covarianza \n",
    "\n",
    "El **vector de medias** se obtiene a partir de la esperanza matemática de las funciones marginales de cada una de las variables aleatorias, como ya se vio en el caso bidimensional:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{X})\\equiv \\boldsymbol{\\mu}_{\\mathbf{X}} = \\left(E(X_1), \\ldots E(X_M) \\right)^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(\\mathbf{V})\\equiv \\boldsymbol{\\mu}_{\\mathbf{V}} \n",
    "= \\left(\\boldsymbol{\\mu}_\\mathbf{X}^\\mathrm{T} , \\boldsymbol{\\mu}_\\mathbf{Y}^\\mathrm{T} \\right)^\\mathrm{T}\n",
    "= \\left(E(\\mathbf{X})^\\mathrm{T}, E(\\mathbf{Y})^\\mathrm{T} \\right)^\\mathrm{T} =\n",
    "\\left(E(X_1), \\ldots E(X_M), E(Y_1), \\ldots E(Y_N)\\right)^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "La **matriz de autocorrelación** del vector aleatorio $\\mathbf{X}$ es:\n",
    "\n",
    "$$\n",
    "\\mathbf{R_{XX}} = E(\\mathbf{XX}^\\mathrm{T}) = \n",
    "\\begin{pmatrix}\n",
    "E(X_1^2) & \\ldots & R_{X_1X_M}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "R_{X_MX_1} & \\ldots & E(X_M^2)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "que resulta **simétrica y semidefinida positiva**. Si todas las componentes son ortogonales entre sí, la matriz resulta diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **matriz de correlación cruzada** de los vectores aleatorios $X$ e $Y$ es:\n",
    "\n",
    "$$\n",
    "\\mathbf{R_{XY}} = E(\\mathbf{XY}^\\mathrm{T}) = \n",
    "\\begin{pmatrix}\n",
    "R_{X_1Y_1} & \\ldots & R_{X_1Y_N}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "R_{X_MY_1} & \\ldots & R_{X_MY_N}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "y se cumple que $\\mathbf{R_{YX}} = \\mathbf{R_{XY}}^\\mathrm{T}$. Por tanto, la matriz de autocorrelación del vector $\\mathbf V = (\\mathbf{X}^\\mathrm{T} , \\mathbf{Y}^\\mathrm{T})^\\mathrm{T}$ es\n",
    "\n",
    "$$\n",
    "\\mathbf{R_{V}} = E(\\mathbf{VV}^\\mathrm{T}) = \n",
    "\\begin{pmatrix}\n",
    "\\mathbf{R_{XX}} & \\mathbf{R_{XY}}\\\\\n",
    "\\mathbf{R_{YX}} & \\mathbf{R_{YY}}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "que también resulta simétrica y semidefinida positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **matriz de autocovarianza** del vector aleatorio $\\mathbf{X}$ es:\n",
    "\n",
    "$$\n",
    "\\mathbf{C_{XX}} = E((\\mathbf{X}-\\mathbf{\\mu_X})(\\mathbf{X}-\\mathbf{\\mu_X})^\\mathrm{T}) = \n",
    "\\begin{pmatrix}\n",
    "\\sigma_{X_1}^2 & \\ldots & C_{X_1X_M}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "C_{X_MX_1} & \\ldots & \\sigma_{X_M}^2\n",
    "\\end{pmatrix} =\n",
    "\\mathbf{R_{XX}}-\\boldsymbol{\\mu}_{\\mathbf X}\\boldsymbol{\\mu}_{\\mathbf X}^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "que resulta **simétrica y semidefinida positiva**. Si todas las componentes son **incorreladas** entre sí, la matriz resulta **diagonal**: $\\mathbf{C_{XX}} = \\mathrm{\\mathbf{diag}}[\\sigma_{X_1}^2\\ldots \\sigma_{X_M}^2]$\n",
    "\n",
    "Las covarianzas de las componentes (elementos fuera de la diagonal) pueden ponerse en función de los coeficientes de correlación:\n",
    "\n",
    "$$\n",
    "C_{X_iX_j} = \\rho_{X_iX_j}\\sigma_{X_i}\\sigma_{X_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **matriz de covarianza cruzada** de los vectores aleatorios $X$ e $Y$ es:\n",
    "\n",
    "$$\n",
    "\\mathbf{C_{XY}} = E((\\mathbf{X}-\\mathbf{\\mu_X})(\\mathbf{Y}-\\mathbf{\\mu_Y})^\\mathrm{T}) = \n",
    "\\begin{pmatrix}\n",
    "C_{X_1Y_1} & \\ldots & C_{X_1Y_N}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "C_{X_MY_1} & \\ldots &  C_{X_MY_N}\n",
    "\\end{pmatrix} =\n",
    "\\mathbf{R_{XX}}-\\boldsymbol{\\mu}_{\\mathbf X}\\boldsymbol{\\mu}_{\\mathbf Y}^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "y se cumple que $\\mathbf{C_{YX}} = \\mathbf{C_{XY}}^\\mathrm{T}$. Por tanto, la matriz de autocovarianza del vector $\\mathbf V = (\\mathbf{X}^\\mathrm{T} , \\mathbf{Y}^\\mathrm{T})^\\mathrm{T}$ es\n",
    "\n",
    "$$\n",
    "\\mathbf{C_{V}} = E((\\mathbf{V}-\\mathbf{\\mu_V})(\\mathbf{V}-\\mathbf{\\mu_V})^\\mathrm{T}) =\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{C_{XX}} & \\mathbf{C_{XY}}\\\\\n",
    "\\mathbf{C_{YX}} & \\mathbf{C_{YY}}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "que también resulta simétrica y semidefinida positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distribuciones condicionadas. Teoremas de Bayes y de la Probabilidad Total\n",
    "\n",
    "Consideremos el vector aleatorio $\\mathbf{X} = (X_1, \\ldots X_{p-1}, X_{p}, X_{p+1} \\ldots X_M)^\\mathrm{T}$. Podemos obtener la **función de distribución condicionada** de unas componentes por otras:\n",
    "\n",
    "$$\n",
    "F_{X_1 \\ldots X_{p-1} | X_p \\ldots X_M} (x_1 , \\ldots x_{p-1} | x_p , \\ldots x_M) = \\frac{F_{X_1 \\ldots X_M}(x_1 , \\ldots x_M)}{F_{X_p \\ldots X_M}(x_p, \\ldots x_M)}\n",
    "$$\n",
    "\n",
    "Considerando que las variables aleatorias son continuas, la  **función de densidad condicionada** es:\n",
    "\n",
    "$$\n",
    "f_{X_1 \\ldots X_{p-1} | X_p \\ldots X_M} (x_1 , \\ldots x_{p-1} | x_p , \\ldots x_M) = \\frac{f_{X_1 \\ldots X_M}(x_1 , \\ldots x_M)}{f_{X_p \\ldots X_M}(x_p, \\ldots x_M)}\n",
    "$$\n",
    "\n",
    "Si las variables aleatorias son discretas, la **función de masa de probabilidad** resulta:\n",
    "\n",
    "$$\n",
    "p_{X_1 \\ldots X_{p-1} | X_p \\ldots X_M} (x_{i_1} , \\ldots x_{i_{p-1}} | x_{i_p} , \\ldots x_{i_M}) = \\frac{p_{X_1 \\ldots X_M}(x_{i_1} , \\ldots x_{i_M})}{p_{X_{p} \\ldots X_M}(x_{i_p}, \\ldots x_{i_M})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regla de la cadena\n",
    "\n",
    "Aplicando sucesiva y ordenadamente la definición de función de densidad condicionada:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_{X_1 \\ldots X_M}(x_1 \\ldots x_M) \n",
    "&= \n",
    "f_{X_1 | X_2 \\ldots X_M} (x_1 | x_2 \\ldots x_{M}) \\ldots f_{X_{M-1} | X_M} (x_{M-1} | x_M) f_{X_M} (x_M)\\\\\n",
    "&= \n",
    "f_{X_M | X_{M-1} \\ldots X_1} (x_M | x_{M-1} \\ldots x_{1}) \\ldots f_{X_2 | X_1} (x_2 | x_1) f_{X_1} (x_1)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Adviértase que no hay un orden establecido por el cual haya que condicionar las funciones de densidad. Además de estas dos formas de construir la cadena de productos, podrían haberse elaborado otras extrayendo en distinto orden las variables condicionantes. Cuando veamos secuencias o procesos temporales, la causalidad establecerá un ordenamiento que sí habrá que respetar.\n",
    "\n",
    "Si las variables son discretas, puede obtenerse una descomposición idéntica utilizando funciones de masa de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ecuación de Chapman-Kolmogorov\n",
    "\n",
    "Se obtiene combinando la definición de función de densidad o de masa de probbailidad con la obtención de funciones marginales. Supone una *extensión del Teorema de la Probabilidad Total*. Veámoslo con unos ejemplos:\n",
    "\n",
    "$$\n",
    "f_{X_3 | X_1}(x_3 | x_1) = \\int_{-\\infty}^{\\infty} f_{X_3X_2 | X_1}(x_3, x_2 | x_1) dx_2 =\n",
    "\\int_{-\\infty}^{\\infty} f_{X_3 | X_2 X_1}(x_3 | x_2 , x_1) f_{X_2}(x_2 | x_1) dx_2\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "f_{X_1 | X_4}(x_1 | x_4) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} f_{X_1 X_2 X_3 | X_4}(x_1 , x_2 , x_3| x_4) dx_2dx_3=\\\\\n",
    "= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} f_{X_1 | X_2 X_3 X_4}(x_1 | x_2 , x_3 , x_4) f_{X_2X_3 | X_4}(x_2, x_3 | x_4) dx_2dx_3\n",
    "$$\n",
    "\n",
    "La ecuación puede aplicarse al caso discreto sin más que sustituir las funciones de densidad por funciones de masa de probabilidad y las integrales por sumatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **función de distribución de un vector aleatorio, $\\mathbf{Y}$, condicionada por otro**, $\\mathbf{X}$, o viceversa, se define extendiendo la definición ya vista para dos variables alatorias\n",
    "\n",
    "$$\n",
    "F_{\\mathbf{Y}|\\mathbf{X}}(\\mathbf{y}|\\mathbf{x}) = \\frac{F_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y})}{F_{\\mathbf{X}}(\\mathbf{x})} \\qquad\n",
    "F_{\\mathbf{X}|\\mathbf{Y}}(\\mathbf{x}|\\mathbf{y}) = \\frac{F_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y})}{F_{\\mathbf{Y}}(\\mathbf{y})}\n",
    "$$\n",
    "\n",
    "A partir de tal definición es inmediato obtener, para el **caso continuo**, la **función de densidad condicionada**:\n",
    "\n",
    "$$\n",
    "f_{\\mathbf{Y}|\\mathbf{X}}(\\mathbf{y}|\\mathbf{x}) = \\frac{f_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y})}{f_{\\mathbf{X}}(\\mathbf{x})} \\qquad\n",
    "f_{\\mathbf{X}|\\mathbf{Y}}(\\mathbf{x}|\\mathbf{y}) = \\frac{f_{\\mathbf{XY}}(\\mathbf{x},\\mathbf{y})}{f_{\\mathbf{Y}}(\\mathbf{y})}\n",
    "$$\n",
    "\n",
    "Y, para el **caso discreto**, la **función de masa de probabilidad condicionada**:\n",
    "\n",
    "$$\n",
    "p_{\\mathbf{Y}|\\mathbf{X}}(\\mathbf{y_j}|\\mathbf{x_i}) = \\frac{p_{\\mathbf{XY}}(\\mathbf{x_i},\\mathbf{y_j})}{p_{\\mathbf{X}}(\\mathbf{x_i})} \\qquad\n",
    "p_{\\mathbf{X}|\\mathbf{Y}}(\\mathbf{x_i}|\\mathbf{y_j}) = \\frac{p_{\\mathbf{XY}}(\\mathbf{x_i},\\mathbf{y_j})}{p_{\\mathbf{Y}}(\\mathbf{y_j})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformaciones Lineales y Teorema del Límite Central\n",
    "\n",
    "Es posible definir transformaciones $\\mathbf{Y} = \\mathbf{g(X)}$ que convierten el vector aleatorio $\\mathbf{X}$ en otro $\\mathbf{Y}$, cuya caracterización conjunta es posible obtener. Entre todas ellas, vamos a prestarle atención a las **transformaciones lineales**. Por ejemplo:\n",
    "\n",
    "$$Y = k_1 X_1 + \\ldots k_M X_M = \\mathbf{k}^\\mathrm{T}\\mathbf{X}$$\n",
    "\n",
    "La media resulta:\n",
    "\n",
    "$$\n",
    "\\mu_Y \\equiv E(Y) = \\mathbf{k}^\\mathrm{T}\\boldsymbol{\\mu}_\\mathbf{X}\n",
    "$$\n",
    "\n",
    "Y la varianza:\n",
    "\n",
    "$$\n",
    "\\sigma_{Y}^2 = E\\left(\\mathbf{k}^\\mathrm{T}(\\mathbf{X}-\\boldsymbol{\\mu}_\\mathbf{X}) (\\mathbf{X}-\\boldsymbol{\\mu}_\\mathbf{X} )^\\mathrm{T}\\mathbf{k}\n",
    "\\right)\n",
    "= \\mathbf{k}^\\mathrm{T}\\mathbf{C_{XX}}\\mathbf{k}\n",
    "$$\n",
    "\n",
    "Si el vector aleatorio $\\mathbf{X}$ tiene sus componentes incorreladas $\\mathbf{C_{XX}} = \\mathrm{\\mathbf{diag}}[\\sigma_{X_1}^2\\ldots \\sigma_{X_M}^2]$ y:\n",
    "\n",
    "$$\n",
    "\\sigma_{Y}^2 = k_1^2\\sigma_{X_1}^2 + \\ldots + k_M\\sigma_{X_M}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En el caso que las componentes del vector $\\mathbf{X}$ sean independientes, y que los coeficiones de la combinación lineal sean todos la unidad, $\\mathbf{k}=(1 \\ldots 1)^\\mathrm{T}$, puede demostrarse que la función de densidad de probabilidad de $Y$ es la **convolución** de las funciones de densidad de probabilidad (en el caso discreto, se trataría de la **convolución discreta** de las funciones de masa de probabilidad):\n",
    "\n",
    "$$\n",
    "f_Y(y) = f_{X_1}(y)* \\ldots * f_{X_M}(y)\n",
    "$$\n",
    "\n",
    "En el caso de las variables aleatorias $X_1 \\ldots X_M$ sean Gaussianas, su convolución resulta también Gaussiana, con media $\\mu_Y = \\mu_1 + \\ldots + \\mu_M$. Como la independencia implica incorrelación, por la varianza es $\\sigma_{Y}^2 = \\sigma_{X_1}^2 + \\ldots + \\sigma_{X_M}^2$. Por tanto $f_Y(y) = N(\\mu_Y, \\sigma_Y^2)$.\n",
    "\n",
    "El **Teorema Central del Límite** establece que, cuando $M$ es muy grande, la función de densidad de la superposición de variables aleatorias independientes tiende a una Gaussiana, independientemente de la caracterización de cada una de ellas. Este resultado justifica el abundante uso de Gaussianas en la práctica, pues frecuentemente nos encontraremos con superposiciones aleatorias de muchos elementos independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La transformación lineal vista anteriormente puede extenderse como sigue:\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\left( \\begin{array}{c}{Y_1} \\\\ \\vdots \\\\ {Y_N}\\end{array}\\right) = \n",
    "\\left[ \\begin{array}{cc} {k_{1,1}} & \\ldots & {k_{1,M}} \\\\ \\vdots & \\ddots & \\vdots \\\\ {k_{N,1}} & \\ldots & {k_{N,M}}\\end{array}\\right]\\left( \\begin{array}{c}{X_1} \\\\ \\vdots \\\\ {X_M}\\end{array}\\right) + \\left( \\begin{array}{c}{m_1} \\\\ \\vdots \\\\ {m_N}\\end{array}\\right) = \n",
    "\\mathbf{K}^\\mathrm{T}\\mathbf{X} + \\mathbf{m}\n",
    "$$\n",
    "\n",
    "Por tanto:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu}_{\\mathbf{Y}} \\equiv E(\\mathbf{Y}) = \n",
    "\\mathbf{K}^\\mathrm{T}\\boldsymbol{\\mu}_{\\mathbf{X}} + \\mathbf{m}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{C_{YY}} = \\mathbf{K}^\\mathrm{T}\\mathbf{C_{XX}}\\mathbf{K}\n",
    "$$\n",
    "\n",
    "Podemos también obtener la matriz de covarianza cruzada entre el resultado y los operandos:\n",
    "\n",
    "$$\n",
    "\\mathbf{C_{YX}} = \\mathbf{K}^\\mathrm{T}\\mathbf{C_{XX}}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
