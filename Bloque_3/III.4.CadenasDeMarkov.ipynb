{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov\n",
    "\n",
    "## Caracterización conjunta de procesos estocásticos y secuencias aleatorias\n",
    "\n",
    "Ya hemos visto los conceptos de secuencias aleatorias y de procesos estocásticos, así como su caracterizaciones marginales. A modo de recordatorio, sean $X(t)$ y $X[n]$ un proceso estocástico y una secuencia aleatoria que, respectivamente, se modelan mediante sendas variables aleatorias para cada instante de tiempo u muestra. La **caracterización marginal** es:\n",
    "\n",
    "$$F_X(x; t) = P\\{X(t)\\leq x\\} \\qquad F_X(x; n) = P\\{X[n]\\leq x\\}$$\n",
    "\n",
    "Para en que el proceso o secuencia tome valores continuos, las funciones de densidad marginales son:\n",
    "\n",
    "$$f_X(x; t) \\qquad f_X(x; n)$$\n",
    "\n",
    "En el caso en que tomen valores discretos, asociamos cada valor posible a un **estado** y nos hallamos en presencia de **cadenas**. Por tanto, <u>una cadena evoluciona entre estados discretos a lo largo de un índice continuo</u>. En este caso recurrimos a las funciones de masa de probabilidad:\n",
    "\n",
    "$$p_X(x_i; t) \\qquad p_X(x_i; n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La **caracterización conjunta** puede definirse conforme a lo visto para variables aleatorias multidimensionales, si bien alteramos levemente la notación para simplificarla. La caracterización conjunta requiere poder conocerla en instantes o muestras arbitrarias:\n",
    "\n",
    "$$\n",
    "F_X(x_M ,\\ldots x_1 ; t_M , \\ldots t_1) = P(X(t_M)\\leq x_M , \\ldots X(t_1)\\leq x_1)\n",
    "$$\n",
    "\n",
    "Sin embargo, a diferencia de lo visto en el caso de variables aleatorios multidimensionales, ahora <u>la ordenación de las variables suele tener un sentido causal</u> (*flecha del tiempo*), cuestión particularmente relevante a la hora de obtener caracterizaciones condicionadas, donde, en términos prácticos, el futuro está condicionado por el presente y el pasado, pero no al revés. Por ejemplo:\n",
    "\n",
    "$$\n",
    "F_X(x_r | x_q , x_p; t_r | t_q , t_p) \\qquad t_p \\leq t_q \\leq t_r\n",
    "$$\n",
    "\n",
    "La funciones de densidad y de masa de probabilidad conjuntas se expresan:\n",
    "\n",
    "$$\n",
    "f_X(x_M ,\\ldots x_1 ; t_M , \\ldots t_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_X(x_{M_i} ,\\ldots x_{1_i} ; t_M , \\ldots t_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Propiedad de Markov\n",
    "\n",
    "Sabemos que en un proceso o secuencia independiente se caracteriza porque las variables aleatorias correspondientes a dos instantes o muestras diferentes no tienen dependencia probbailística entre sí. Ya hemos visto que tales procesos o secuencias suelen denominarse **blancos**.\n",
    "\n",
    "La generalización más sencilla que puede hacerse a partir de tales procesos o secuencias es que, en vez de ser independientes, cumplan la **propiedad de Markov**. La propiedad de Markov establece que la variable aleatoria correspondiente al instante o muestra actual depende probabilísticamente sólo de la inmediatamente anterior pero, dada ésta, no de las que sean más antiguas. De forma equivalente, si conocemos el presente el pasado no nos interesa para realizar predicciones sobre el futuro.\n",
    "\n",
    "$$\n",
    "F_X(x_r | x_q x_p; t_r | t_q , t_p) = F_X(x_r | x_q ; t_r | t_q) \\qquad t_p \\leq t_q \\leq t_r\n",
    "$$\n",
    "\n",
    "La propiedad de Markov puede aplicarse a las funciones de densidad y, en su caso, a las funciones de masa de probabilidad, como haremos en lo sucesivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La propiedad de Markov puede también enunciarse diciendo que **dado el presente el pasado y el futuro son condicionalmente independientes**, si bien ello requiere una formulación que no es causal:\n",
    "\n",
    "$$\n",
    "f_X(x_r , x_p| x_q; t_r , t_p | t_q) = f_X(x_p | x_r , x_q ; t_p | t_r , t_q) f_X(x_r | x_q ; t_r | t_q) =\\\\\n",
    "= f_X(x_p | x_q ; t_p | t_q) f_X(x_r | x_q ; t_r | t_q) \\qquad t_p \\leq t_q \\leq t_r\n",
    "$$\n",
    "\n",
    "La propiedad de Markov nos permite **simplificar la regla** de la cadena para obtener la caracterización conjunta a partir de las condicionadas:\n",
    "\n",
    "$$\n",
    "f_X(x_m, \\ldots x_1; t_m \\ldots t_1) =\\\\ \n",
    "f_X(x_M | x_{M-1} ,\\ldots x_1 ; t_M ,\\ldots t_1) f_X(x_{M-1} | x_{M-2} ,\\ldots x_1 ; t_{M-1} ,\\ldots t_1) \\ldots f_X(x_2 | x_1 ; t_2 , t_1) f_X(x_1 ; t_1) =\\\\\n",
    "=f_X(x_M | x_{M-1} ; t_M , t_{M-1}) f_X(x_{M-1} | x_{M-2} ; t_{M-1},t_{M-2}) \\ldots f_X(x_2 | x_1 ; t_2 , t_1) f_X(x_1 ; t_1) \n",
    "$$\n",
    "\n",
    "Según se vio en la parte introductoria, el proceso o secuencia de Markov es **estacionario** si la caracterización conjunta es **invariable frente a desplazamientos temporales**:\n",
    "\n",
    "$$\n",
    "f_X(x_m, \\ldots x_1; t_m \\ldots t_1) = f_X(x_m, \\ldots x_1; t_m -\\tau ,\\ldots t_1 - \\tau)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cadenas discretas de Markov\n",
    "\n",
    "En lo que sigue nos restringiremos al estudio de cadenas discretas de Markov, que por tanto **toman valores en un conjunto discreto de estados, obtenidas muestreando la variable temporal** con un periodo $T_0$, de modo que $X[n] = X(nT_0)$. Para simplificar la nomenclatura, vamos a suponer que los valores o **estados** que puede alcanzar la cadena son $e_1, \\ldots e_n \\ldots$ Además:\n",
    "\n",
    "* $p_i(n) \\equiv p_X(e_i ; n) = P(X[n]=e_i)$\n",
    "* Si el número de estados $E$ es finito pueden representarse las probabilidades de cada estado en cada instante $n$ mediante un vector fila: $\\boldsymbol{\\pi}(n) = [p_1(n) \\ldots p_E(n)]$ \n",
    "* La probabilidad de pasar del estado $e_i$ en el instante $m$ al estado $e_j$ en el instante $n$ se representa mediante la probabilidad de transición $p_{ij}(m,n) \\equiv p_X(e_j | e_i ; n | m) = P(X[n] = e_j | X[m] = e_i)$\n",
    "* La tabla con todas las probablidades de transición entre el instante $m$ y el $n$ puede expresarse mediante una matriz estocástica (sus filas suman uno) $\\Pi_{n | m} \\equiv P(m,n)$ cuyos elementos en la fila $i$ y columna $j$ son $p_{ij}(m,n)$\n",
    "* Conforme al Teorema de la Probabilidad Total: $\\pi(n) = \\pi(m) \\Pi_{n | m} \\equiv \\pi(m)\\mathbf{P}(m,n)$ (adviértase que se opera en esta fomulación con vectores fila de probabilidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\boldsymbol{\\Pi}_{n | m} \\equiv \\mathbf{P}(m,n) = \n",
    "\\begin{bmatrix}\n",
    "  P(X[n] = e_1 | X[m] = e_1) & \\ldots & P(X[n] = e_E | X[m] = e_1)\\\\\n",
    "  \\vdots & \\ddots & \\vdots\\\\\n",
    "  P(X[n] = e_M | X[m] = e_1) & \\ldots & P(X[n] = e_M | X[m] = e_M) \n",
    "\\end{bmatrix} =\\\\\n",
    "\\begin{bmatrix}\n",
    "  p_{11}(m,n) & \\ldots & p_{1E}(m,n)\\\\\n",
    "  \\vdots & \\ddots & \\vdots\\\\\n",
    "  p_{E1}(m,n) & \\ldots & p_{EE}(m,n)\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Pueden combinarse dos o más transiciones, dando lugar a una versión matricial de las ecuaciones de Chapman-Kolmogorov. Considerando $p < q < r$:\n",
    "\n",
    "$$\n",
    "\\left. \\begin{array}{c}\n",
    "\\boldsymbol{\\pi}(q) = \\boldsymbol{\\pi}(p)\\mathbf{P}(p,q)\\\\\n",
    "\\boldsymbol{\\pi}(r) = \\boldsymbol{\\pi}(q)\\mathbf{P}(q,r)\n",
    "\\end{array} \\right\\} \n",
    "\\boldsymbol{\\pi}(r) =  \\boldsymbol{\\pi}(p)\\left(\\mathbf{P}(p,q)\\mathbf{P}(q,r)\\right) = \n",
    "\\boldsymbol{\\pi}(p)\\mathbf{P}(p,r)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una cadena de Markov se denomina **homogénea** si la matriz de transición $\\mathbf{P}(m,n)$ entre dos instantes arbitrarios $m$, $n$, depende sólo de su separación $k = n-m$ y no de los instantes concretos. Es un concepto que no debe confundirse con la estacionariedad, que se aplica a la caracterización conjunta en vez de a las transiciones. Por tanto, si la cadena es homogénea:\n",
    "\n",
    "$$\\mathbf{P}(m, n)\\equiv \\mathbf{P}(n-m) = \\mathbf{P}(k)\\\\\n",
    "\\mathbf{P}(m, m+1)\\equiv \\mathbf{P}(1) \\equiv \\mathbf{P}$$\n",
    "\n",
    "Por tanto,\n",
    "\n",
    "$$\n",
    "\\mathbf{P}(k) = \\mathbf{P}^k\\\\\n",
    "\\boldsymbol{\\pi}(m+k) = \\boldsymbol{\\pi}(m) \\mathbf{P}^k\n",
    "$$\n",
    "\n",
    "Adviértse que, en general, la distribución de probabilidades de los estados varía en cada instante de tiempo, $\\boldsymbol{\\pi}(m+1) = \\boldsymbol{\\pi}(m) \\mathbf{P}$. Puede, no obstante, alcanzarse una distribución de estados $\\boldsymbol{\\pi_\\infty}$, que se mantenga estacionaria en el tiempo, si se cumple:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\pi_\\infty} = \\boldsymbol{\\pi_\\infty} \\mathbf{P}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Es habitual representar gráficamente las cadenas homogéneas de Markov mediante **grafos dirigidos**, donde los vértices representan los estados y las aristas las transiciones, estando etiquetadas por las respectivas probabilidades. \n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "Supóngase un modelo meteorológico en el que los días pueden ser sólo soleados o lluviosos. El tiempo del día presente se modela como una cadena de Markov homogénea, considerando sólo el día anterior. Si este fue soleado, la probabilidad de que el día actual también lo sea es de 4/5. Sin embargo, si el día anterior fue lluvioso, la probabilidad de que el actual sea soleado es de ½.\n",
    "\n",
    "1. Modele los estados, probabilidades y matriz de transición de la cadena de Markov\n",
    "2. Si ayer fue soleado, ¿cuál es la probabilidad de que mañana también lo sea? ¿Y si fue lluvioso? Hoy todavía no he abierto la ventana y no sé qué día hace.\n",
    "Suponga que un día tiene una probabilidad de ser soleado de 2/3.\n",
    "3. ¿Cuál será la probabilidad de que al día siguiente también haga sol? ¿Y de que llueva?\n",
    "4. ¿Existe la distribución estacionaria para esta cadena de Markov? ¿Por qué?\n",
    "5. Indique la matriz de transición de un clima tal que casi siempre esté soleado, pero que si un día está lluvioso ya será imposible que vuelva a hacer sol."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
